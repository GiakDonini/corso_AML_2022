{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corso_AML_2022/blob/main/notebooks/es5/AML_2022_5_VisionTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz5n18BbS4Ec"
      },
      "source": [
        "# Advanced Machine Learning for Physics 2021-2022\n",
        "## Hands-on session 5\n",
        "\n",
        "In this session, we will try to implement the new trend in image classification for the hadronic jet classification task: Transformers for Computer Vision. Since Alexey Dosovitskiy et al. successfully applied a Transformer on a variety of image recognition benchmarks, there have been an incredible amount of follow-up works showing that CNNs might not be optimal architecture for Computer Vision anymore. \n",
        "\n",
        "Remember, in this case the comparison between CNN and transformers is not fair. CNNs have been built to leverage our priors information on how images are structured while transformers need have to learn all these invariances from data.\n",
        "In general transformer will be competitive with CNN on large dataset or with pre-training.\n",
        "\n",
        "We will try to check for those differences  by implementing a Vision Transformer ourselves and train it on the datasetthat we saw in Session 3:\n",
        "\n",
        "\n",
        "At the extreme energies of the Large Hadron Collider, massive particles can be produced with such high Lorentz boost that their decays into hadrons (hadron jets) are collimated in such a way that the resulting particles overlap. Deducing whether the substructure of an observed jet is due to a single low-mass particle or to multiple decay objects of a high-mass particle is an important problem in LHC data analysis. Traditional approaches are based on high-level observables built from theoretical models of energy deposition in calorimeters, but the complexity of the data makes this task an excellent candidate for the application of deep learning tools. The data collected by the detector can in fact be represented as a two-dimensional image, lending itself to the natural application of image classification techniques.\n",
        "\n",
        "A description of the dataset and classification results obtained with standard supervised techniques are available [here](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.93.094034).\n",
        "\n",
        "A reduced size dataset is available in the github folder:\n",
        "[dataset](https://github.com/stefanogiagu/corso_AML_2022/tree/main/notebooks/es3). \n",
        "\n",
        "Based on a modified version of several examples available in the web and on the original paper: \n",
        "\n",
        "[Dosovitskiy et al., AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://arxiv.org/pdf/2010.11929.pdf).\n",
        "\n",
        "The architecture used is derived from this paper:\n",
        "[Xiong et al., On Layer Normalization in the Transformer Architecture](http://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf).\n",
        "\n",
        "\n",
        "Andrea e Stefano - v1.0 - 2.4.2022"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/es5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "douXx6JLquFf",
        "outputId": "24b57e5d-0a40-43d4-8e87-3f02fa646025"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/es5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4bYFRuhYGv8"
      },
      "source": [
        "**Read dataset and preporcess it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "mnGcflE1uRVR",
        "outputId": "5b45f8c0-e70c-48ce-9cf7-5c60c71cf544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape:  (20000, 32, 32)\n",
            "(20000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# jet images, 32x32 pixels (eta, phi) plane, with energy deposit on each calorimetric cell\n",
        "# targets: binary label 0, 1, nornmal and merged jet\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "with np.load('simCLR_dataset.npz') as f:\n",
        "    train_features = f['train_features']\n",
        "    train_targets = f['train_targets']\n",
        "\n",
        "print(\"data shape: \",train_features.shape)\n",
        "print(train_targets.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i+1)\n",
        "  ax.imshow(train_features[i], cmap='Blues')\n",
        "  ax.set_title(train_targets[i])\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SBqjkuSpXzb"
      },
      "source": [
        "## Data is not similar to \"real natural images \" Check the distribution of values!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "uKgBErbIpXzd",
        "outputId": "dea4656d-f594-4096-8bb3-ed9bdc942764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximun value :  399.883\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdWElEQVR4nO3de5xcZZ3n8c+X5iYgyJB2XBJyAYIal1mQNjDqeJkBjZchrAMSECfs4GQYiTfWXcMOosYbOOouvmCEjGZQWAgRHG2GsBEUcETjpLkIJhppYjCJF8I1MiKQ5Ld/nKeZk8pT3VVJna7qru/79apX1znP85zzq6e761fPec45pYjAzMys1m7tDsDMzDqTE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUHYLpO0StLr2h1HO0n6r5LWS3pS0tGZ8pB0eAX77bi+l3STpLnDlF8m6cOjGZPtHPk6CBuOpHXAuyLiltK6M9O6VzexnanAz4E9ImJLa6NsP0kPAOdGxDfrlAcwPSIGRzey7WJYR83vchT2eSZN/q1Y5/AIwsYFSbu3OYQpwKo2x2DWUk4QtsskrZN0fHo+U9KApM2SfiPp86nad9PPx9NhmD+WtJuk8yU9KOkhSV+VdEBpu3+Zyh6R9OGa/XxU0nWSrpK0GTgz7fsHkh6X9CtJl0jas7S9kPRuSfdL+q2kj0s6TNL3U7xLy/VrXmM2Vkl7SXoS6AF+lEYSI/XXAan9prS98yXtlsp6JH1O0sOSfi5pfoo7mwAzfbI0bfu36fBTXyq7EpgM3JD6/3+m9cel1/+4pB+VD1dJui310R1pe9+SNCGV7Z36/pHUdqWkPyy1e5eklwKXAX+c9vl4Kr9C0idK+3mrpHvSdr4v6Y9KZR+StDHtf42kPxupf62FIsIPP+o+gHXA8TXrzgS+l6sD/AB4Z3q+H3Bcej4VCGD3Uru/AgaBQ1PdrwNXprIZwJPAq4E9gc8Cz5b289G0fBLFB53nAccAxwG7p/39BHh/aX8BfBPYH3gZ8DTw7bT/A4DVwNw6/VA31tK2Dx+mH58rB76a4nh+ivNnwFmp7OwUxyTgQOCW2n6r9/tJffJ74M0UCevTwIp6v0tgIvBIqr8bcEJa7k3ltwEPAEek/r0NuDCV/Q1wA7BP2tcxwP6ldu/K/a2kdVcAn0jPjwYeAo5N25mb4twLeDGwHji49Dd0WLv/J7rp4RGENeIb6dPd4+lT4D8MU/dZ4HBJEyLiyYhYMUzddwCfj4i1EfEkcB4wJ31aPhm4ISK+FxHPABdQvFGW/SAivhER2yLiqYi4MyJWRMSWiFgHXA68tqbNZyJic0SsAn4MfCvt/wngJoo3rGZjbZikHmAOcF5E/DbF+TngnanK24GLI2JDRDwGXNjM9inejJdFxFbgSuC/DFP3DGBZqr8tIm4GBigSxpB/ioifRcRTwFLgqLT+WeAgiqS3NfX95iZjBZgHXB4RP0zb+QpF4j4O2EqRKGZI2iMi1kXEiCM0ax0nCGvESRHxgqEH8O5h6p5F8Ynzp+mww1uHqXsw8GBp+UGKT/9/mMrWDxVExO8oPt2WrS8vSDpC0r9I+nU67PQpYEJNm9+Unj+VWd5vJ2JtxgRgj8y2Jpb2U35d273GBvy69Px3wN7DJLEpwCk1yf/VwH8aZntD/XMlsBxYIumXkj4jaY8mYx2K4b/XxHAIxahhEHg/xcjoIUlLJB28E/uwneQEYS0VEfdHxGnAC4GLgOsk7cuOn/4BfknxBjFkMrCF4k37VxSHWQCQ9DyKT6zb7a5m+YvATynOFtof+F+Adv7VNBxrMx6m+PRdu62N6fl2r5vizbJVavtrPcVhsheUHvtGxIijloh4NiI+FhEzgFcCbwX+soF91loPfLImhn0i4pq0n6ujOANqStrWRSPFZq3jBGEtJekMSb0RsQ14PK3eBmxKPw8tVb8G+ICkaZL2o/jEf20Up8FeB/y5pFemieOPMvKb/fOBzcCTkl4C/G2rXtcIsTYsHfpZCnxS0vMlTQHOBa5KVZYC75M0UdILgA+17iXwG7bv/6so+viNaXJ8b0mvkzSpTvvnSHq9pCPTIbPNFElvW519Tqo3+Q/8I3C2pGNV2FfSW1LfvFjSn0rai2Ju5ak6+7CKOEFYq80CVqUzey4G5qT5gd8BnwTuSIcSjgMWUxyq+C7FNRK/B94DkOYI3gMsofhU/STFZObTw+z7g8DpwG8p3niubeHrqhvrTngP8O/AWuB7wNVp+1DE/S3gXuBuYBnFSGXrzgZe8mng/NT/H4yI9cBsipHWJopP8/+Dxt4XXkSRxDdTnAxwO0X/1PoOxem/v5b0cG1hRAwAfw1cAjxGcSLAmal4L4o5mIcpDnW9kGLux0aJL5SzMSF9an+c4vDRz9sdz2iR9CbgsoiYMmJlsxbzCMI6lqQ/l7RPmsP4LHAfxSmQ45ak50l6s6TdJU0EPgL8c7vjsu7kBGGdbDbF5PAvgekUh6vG+5BXwMcoDrfcTXH45oK2RmRdy4eYzMwsyyMIMzPLcoIwM7Osdt8Bs2UmTJgQU6dObXcYZmZjyp133vlwRPTmysZNgpg6dSoDAwPtDsPMbEyR9GC9Mh9iMjOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoKwSkxdcCNTF9zY7jDMbBc4QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWValCULSLElrJA1KWpApP1vSfZLukfQ9STPS+qmSnkrr75F0WZVxmpnZjir7RjlJPcClwAnABmClpP6IWF2qdnVEXJbqnwh8HpiVyh6IiKOqis/MzIZX5QhiJjAYEWsj4hlgCTC7XCEiNpcW9wWiwnjMzKwJVSaIicD60vKGtG47ks6R9ADwGeC9paJpku6WdLukP6kwTjMzy2j7JHVEXBoRhwEfAs5Pq38FTI6Io4Fzgasl7V/bVtI8SQOSBjZt2jR6QZuZdYEqE8RG4JDS8qS0rp4lwEkAEfF0RDySnt8JPAAcUdsgIhZFRF9E9PX29rYscDMzqzZBrASmS5omaU9gDtBfriBpemnxLcD9aX1vmuRG0qHAdGBthbFaRXxXV7Oxq7KzmCJii6T5wHKgB1gcEaskLQQGIqIfmC/peOBZ4DFgbmr+GmChpGeBbcDZEfFoVbGamdmOKksQABGxDFhWs+6C0vP31Wl3PXB9lbFZ63mkYDa+tH2S2szMOpMThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWVVepqrdQef3mo2PnkEYWZmWU4QZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUEYWZmWb4OwkZF+VqJdRe+pY2RmFmjPIIwM7MsJwgzM8tygjAzsywnCDMzy6p0klrSLOBioAf4UkRcWFN+NnAOsBV4EpgXEatT2XnAWansvRGxvMpYrTm+QZ/Z+FdZgpDUA1wKnABsAFZK6h9KAMnVEXFZqn8i8HlglqQZwBzgZcDBwC2SjoiIrVXFa41xYjDrHlUeYpoJDEbE2oh4BlgCzC5XiIjNpcV9gUjPZwNLIuLpiPg5MJi2Z2Zmo6TKQ0wTgfWl5Q3AsbWVJJ0DnAvsCfxpqe2KmrYTqwnTzMxy2j5JHRGXRsRhwIeA85tpK2mepAFJA5s2baomQDOzLlVlgtgIHFJanpTW1bMEOKmZthGxKCL6IqKvt7d3F8M1M7OyKhPESmC6pGmS9qSYdO4vV5A0vbT4FuD+9LwfmCNpL0nTgOnAv1UYq42iqQtu9GS32RhQ2RxERGyRNB9YTnGa6+KIWCVpITAQEf3AfEnHA88CjwFzU9tVkpYCq4EtwDk+g8nMbHRVeh1ERCwDltWsu6D0/H3DtP0k8MnqorNm+BO/Wfdp+yS1mZl1JicIMzPL8vdBWF0+rGTW3TyCMDOzLCcIMzPLcoIwM7Msz0FY2/h7qs06m0cQZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluWzmGwHvoLazMAjCDMzq8MJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLIqTRCSZklaI2lQ0oJM+bmSVku6V9K3JU0plW2VdE969FcZp5mZ7aiy6yAk9QCXAicAG4CVkvojYnWp2t1AX0T8TtLfAp8BTk1lT0XEUVXFZ51l6NoL39XVrHNUOYKYCQxGxNqIeAZYAswuV4iIWyPid2lxBTCpwnjMzKwJVSaIicD60vKGtK6es4CbSst7SxqQtELSSbkGkualOgObNm3a9YjNzOw5HXGrDUlnAH3Aa0urp0TERkmHAt+RdF9EPFBuFxGLgEUAfX19MWoBm5l1gSpHEBuBQ0rLk9K67Ug6Hvg74MSIeHpofURsTD/XArcBR1cYq5mZ1agyQawEpkuaJmlPYA6w3dlIko4GLqdIDg+V1h8oaa/0fALwKqA8uW1mZhWr7BBTRGyRNB9YDvQAiyNilaSFwEBE9AN/D+wHfE0SwC8i4kTgpcDlkrZRJLELa85+MjOziilifBy67+vri4GBgXaHMWZ12i2+fbqr2eiQdGdE9OXKfCW1mZllOUGYmVmWE4SZmWU5QZiZWVZHXChn7dNpk9Nm1jk8gjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsyxfB2EdqXx9hm/cZ9YeHkGYmVmWRxBdyldQm9lIPIIwM7MsJwjreFMX3OgRj1kbOEGYmVmWE4SZmWUNmyAknZJ+TtuZjUuaJWmNpEFJCzLl50paLeleSd+WNKVUNlfS/ekxd2f2b2ZmO2+kEcR56ef1zW5YUg9wKfAmYAZwmqQZNdXuBvoi4o+A64DPpLZ/AHwEOBaYCXxE0oHNxmBmZjtvpNNcH5H0LWCapP7awog4cZi2M4HBiFgLIGkJMBtYXWp/a6n+CuCM9PyNwM0R8WhqezMwC7hmhHjNzKxFRkoQbwFeDlwJfK7JbU8E1peWN1CMCOo5C7hpmLYTaxtImgfMA5g8eXKT4ZmZ2XCGTRAR8QywQtIrI2JTVUFIOgPoA17bTLuIWAQsAujr64sKQjMz61rDJghJNwCRnu9QPsIhpo3AIaXlSWld7T6OB/4OeG1EPF1q+7qatrcNF6uZmbXWSIeYPpt+vg14EXBVWj4N+M0IbVcC09MZUBuBOcDp5QqSjgYuB2ZFxEOlouXAp0oT02/gPybMrUv5Bn5mo2ukQ0y3A0j6XET0lYpukDQwQtstkuZTvNn3AIsjYpWkhcBARPQDfw/sB3wtjVB+EREnRsSjkj5OkWQAFg5NWNvO89XIZtaMRm/Wt6+kQ0tnJE0D9h2pUUQsA5bVrLug9Pz4YdouBhY3GJ+ZmbVYowniA8Btktam5anA31QSkZmZdYRGb7VxG8VcwWPAtvT89opiMjOzDtDoCOKrwGbgC2n5dIprI06pIigzM2u/RhPEf46I8m0ybpW0um5ts4oNTbj7bCaz6jR6iOkuSccNLUg6Fhj2LCYzMxvbGh1BHAN8X9Iv0vJkYI2k+4BIN9szM7NxpNEEMavSKMzMrOM0lCAi4sGqA7Hq+AI5M9sZ/kY5MzPLcoIwM7MsJwgb06YuuNGH0Mwq4gRhZmZZThBmZpblBGFmZllOEGZmltXohXI2xnTbxK2/bc6s9TyCMDOzLCcIMzPLcoIwM7OsShOEpFmS1kgalLQgU/4aSXdJ2iLp5JqyrZLuSY/+KuM0M7MdVTZJLakHuBQ4AdgArJTUHxHlLxr6BXAm8MHMJp6KiKOqis/MzIZX5VlMM4HBiFgLIGkJMBt4LkFExLpUtq3COKzL+NvmzFqjygQxEVhfWt4AHNtE+70lDQBbgAsj4hu1FSTNA+YBTJ48eRdCHT+67fRWM6tOJ09ST4mIPuB04P9IOqy2QkQsioi+iOjr7e0d/QjNzMaxKhPERuCQ0vKktK4hEbEx/VwL3AYc3crgzMxseFUmiJXAdEnTJO0JzAEaOhtJ0oGS9krPJwCvojR3YdYI3wrcbNdUliAiYgswH1gO/ARYGhGrJC2UdCKApFdI2gCcAlwuaVVq/lJgQNKPgFsp5iCcIMzMRlGl92KKiGXAspp1F5Ser6Q49FTb7vvAkVXGZmZmw/PN+mzc8438zHZOJ5/FZGZmbeQEYWZmWU4Q1lV8ZpNZ4zwHYV3J8xJmI/MIwszMspwgzMwsywnCzMyynCDMzCzLk9TjhM/MMbNW8wjCup5PfTXLc4IwM7MsJwgzM8tygjAzsywnCLPEcxFm23OCMDOzLCcIMzPL8nUQZjV8Iz+zghPEGObj5WZWpUoPMUmaJWmNpEFJCzLlr5F0l6Qtkk6uKZsr6f70mFtlnGZmtqPKEoSkHuBS4E3ADOA0STNqqv0COBO4uqbtHwAfAY4FZgIfkXRgVbGa1eMzm6ybVTmCmAkMRsTaiHgGWALMLleIiHURcS+wrabtG4GbI+LRiHgMuBmYVWGsZmZWo8o5iInA+tLyBooRwc62nVhbSdI8YB7A5MmTdy7KMcifaM1sNIzp01wjYlFE9EVEX29vb7vDMTMbV6pMEBuBQ0rLk9K6qtuamVkLVHmIaSUwXdI0ijf3OcDpDbZdDnyqNDH9BuC81odo1hhfG2HdqLIRRERsAeZTvNn/BFgaEaskLZR0IoCkV0jaAJwCXC5pVWr7KPBxiiSzEliY1pmZ2Sip9EK5iFgGLKtZd0Hp+UqKw0e5touBxVXGZ2Zm9Y3pSWqzdvC1EdYtnCDMzCzLCcLMzLKcIMzMLMsJosP5eHfn8u/GxjsnCDMzy3KCMDOzLCcIMzPL8jfKme0i34bDxiuPIMxayBPXNp44QZiZWZYPMY0R/lRqZqPNCcKsAp6XsPHAh5jMzCzLCcLMzLKcIMzMLMsJwszMspwgzCrmayNsrPJZTB3Kbyjjz9Dv1Gc12VhR6QhC0ixJayQNSlqQKd9L0rWp/IeSpqb1UyU9Jeme9LisyjjNzGxHlY0gJPUAlwInABuAlZL6I2J1qdpZwGMRcbikOcBFwKmp7IGIOKqq+MzMbHhVHmKaCQxGxFoASUuA2UA5QcwGPpqeXwdcIkkVxmTWdr6IzsaKKhPERGB9aXkDcGy9OhGxRdITwEGpbJqku4HNwPkR8a+1O5A0D5gHMHny5NZG3waedzCzTtKpZzH9CpgcEUcD5wJXS9q/tlJELIqIvojo6+3tHfUgzczGsyoTxEbgkNLypLQuW0fS7sABwCMR8XREPAIQEXcCDwBHVBirWVv4FFjrZFUmiJXAdEnTJO0JzAH6a+r0A3PT85OB70RESOpNk9xIOhSYDqytMFYzM6tR2RxEmlOYDywHeoDFEbFK0kJgICL6gS8DV0oaBB6lSCIArwEWSnoW2AacHRGPVhWrWbt54to6UaUXykXEMmBZzboLSs9/D5ySaXc9cH2VsZmZ2fA6dZLarGt5XsI6hW+10QH8ZmBmncgjCLMO5ZGEtZtHEGYdzhPY1i4eQZiZWZYThNkY4sNONpqcIEaZ/8HNbKzwHESbOEnYrvC8hI0GjyDMzCzLCcJsjPNhS6uKE4TZOOFEYa3mBGFmZlmepB4l/mRno8UT2NYqHkGYjWM+7GS7wiMIsy6QSxIeXdhIPIIw61IeXdhIPIIw63Kes7B6nCDM7Dk+FGVlThAV8vDdxoOhv2Mniu5TaYKQNAu4GOgBvhQRF9aU7wV8FTgGeAQ4NSLWpbLzgLOArcB7I2J5lbGa2fCG+8Dj5DE+VZYgJPUAlwInABuAlZL6I2J1qdpZwGMRcbikOcBFwKmSZgBzgJcBBwO3SDoiIrZWFW+zn5Jq6/s4rnWzRkfL/t8YW6ocQcwEBiNiLYCkJcBsoJwgZgMfTc+vAy6RpLR+SUQ8Dfxc0mDa3g8qjHc7jR6LzdXzoSWzvKr/N5yAWqvKBDERWF9a3gAcW69ORGyR9ARwUFq/oqbtxNodSJoHzEuLT0paUyeWA4AnRoj3AOAJXVS/XBdlt5Hbdu26kZYnAA+PEN/OaOR172y7kerUK9/V/qqqr+rF1qp27q/m2g1Xp25fNfg/6v7afv2UuluNiEoewMkU8w5Dy+8ELqmp82NgUmn5AYpf0CXAGaX1XwZO3oVYFu1qnXrlufW16xpYHqjodzDi6x5r/VVVX7m/xk5/NdNX7q/m+6v8qPJCuY3AIaXlSWldto6k3Sky2iMNtm3GDS2oU688t7523UjLVdnZ/bi/Wt/O/dVcu+HqNNNXufXurwa3q5RJWi694f8M+DOKN/eVwOkRsapU5xzgyIg4O01Svy0i3i7pZcDVFPMOBwPfBqZHhZPU7SRpICL62h3HWOC+ao77qznur+1VNgcRxZzCfGA5xWmuiyNilaSFFMO4fopDR1emSehHKc5cItVbSjGhvQU4Z7wmh2RRuwMYQ9xXzXF/Ncf9VVLZCMLMzMY236zPzMyynCDMzCzLCcLMzLKcIDqYpEMlfVnSde2OpVNJ2lfSVyT9o6R3tDueTue/qeZIOin9bV0r6Q3tjme0OUFURNJiSQ9J+nHN+lmS1kgalLRguG1ExNqIOKvaSDtPk333NuC6iPhr4MRRD7YDNNNf3fo3VdZkf30j/W2dDZzajnjbyQmiOlcAs8orSjcwfBMwAzhN0gxJR0r6l5rHC0c/5I5xBQ32HcVFlEO3dBnPp0IP5woa7y/buf46P5V3FX8fREUi4ruSptaszt7AMCI+Dbx1dCPsXM30HcV9uiYB99ClH3ia7K/VdLlm+kvST4ALgZsi4q5RDbQDdOU/VBvlbmC4w00Ih0g6SNJlwNHp+zG6Wb2++zrwF5K+yOjdMmEsyPaX/6bqqvf39R7geOBkSWe3I7B28giig0XEIxTHPq2OiPh34L+1O46xwn9TzYmILwBfaHcc7eIRxOhq9U0Iu4n7rjnur+a4vzKcIEbXSmC6pGmS9qS491R/m2MaK9x3zXF/Ncf9leEEURFJ11B8A96LJW2QdFZEbAGGbmD4E2Bp+e62VnDfNcf91Rz3V+N8sz4zM8vyCMLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLGFUlPNlDn/ZL2afF+Dx76jgVJR0l6c6nsxJFu7d7gPp4n6XZJPZKm1t6uuslt3SLpwF2NycY3JwjrRu8HWpogIuKXEXFyWjwKeHOprD8iLmzBbv4K+HpEtOK25lcC727Bdmwcc4KwcUnS6yTdJuk6ST+V9H9VeC9wMHCrpFtT3TdI+oGkuyR9TdJ+af06SR9L6++T9JK0/rWS7kmPuyU9f+gTfbpNw0Lg1FR+qqQzJV2S2vZKul7SyvR4Vb1tZl7WO4BvZl7r3pL+KcV4t6TXp/X7SFoqabWkf5b0Q0l9qVk/cFor+9zGHycIG8+OphgtzAAOBV6V7s75S+D1EfF6SRMovgzm+Ih4OTAAnFvaxsNp/ReBD6Z1HwTOiYijgD8BnhqqHBHPABcA10bEURFxbU1MFwP/OyJeAfwF8KWRtgmQEs+hEbEu8zrPKXYdR1K86X9F0t4UI4THImIG8GHgmFKcjwF7STqofvdZt3OCsPHs3yJiQ0Rso/hCoamZOsdRJJA7JN0DzAWmlMq/nn7eWWp/B/D5NBp5QbqPT6OOBy5J++oH9k8jlpG2OQF4vM42Xw1cBRARPwUeBI5I65ek9T8G7q1p9xDFaMosy98HYePZ06XnW8n/vQu4OSLqHW4Z2sZz7SPiQkk3Uswz3CHpjcDvG4xpN+C4iKitv8M205v9kKeAvRvcR6P2pmakYlbmEYR1o98CQ8f4VwCvknQ4gKR9JR0xXGNJh0XEfRFxEcVtol8yzPZrfYviW8qGtnVUI9tMh4R60qGjWv9KMT9Bin0ysIZiVPL2tH4GcGRpvwJeBKwb7rVad3OCsG60CPh/km6NiE3AmcA1ku6luA107Rt+rfenCel7gWeBm2rKbwVmDE1S15S9F+iTdK+k1fzHt7uNtE0oksurM+v/AdhN0n3AtcCZEfF0Wt+b9vMJYBXwRGpzDLCiycNj1mV8u2+zMULSy4EPRMQ7G6zfA+wREb+XdBhwC/DiiHhG0sVAf0R8u8KQbYzzHITZGBERd0m6VVJPg9dC7ENxOu8eFHMt705nWQH82MnBRuIRhJmZZXkOwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLOv/A7iWHErEnbYfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_bin = 128\n",
        "print(\"maximun value : \",np.max(train_features))\n",
        "logbins = np.geomspace(train_features[train_features>0].min(), train_features.max(), n_bin)\n",
        "plt.figure(111)\n",
        "plt.hist(train_features.ravel(), bins=logbins,density=True)\n",
        "plt.xscale('log')\n",
        "plt.ylabel(\"pdf\")\n",
        "plt.xlabel(\"Intensities (log)\")\n",
        "plt.title(\"Histogram of log intensities\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GKhn15RpXzh"
      },
      "source": [
        "## To visualize the rich structure of the data is better to show the logbins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "C0FGMuyopXzi",
        "outputId": "0315ce47-0549-4cbe-cac3-ca9027e43834"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i+1)\n",
        "  ax.imshow(np.digitize(train_features[i],logbins)/n_bin, cmap='Blues')\n",
        "  ax.set_title(train_targets[i])\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h3ZK-YDupfY",
        "outputId": "bd92db66-3a75-4030-9e98-ccd561fb3dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "0.11.1+cu111\n"
          ]
        }
      ],
      "source": [
        "# some useful libs\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjNHxiStvFm2",
        "outputId": "56aebbcb-0669-4418-ade7-a714bba138ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of GPUs available:  1\n",
            "First GPU type:  Tesla K80\n",
            "Computation device: cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define device to use (cpu/gpu)\n",
        "if torch.cuda.is_available():\n",
        "  print('# of GPUs available: ', torch.cuda.device_count())\n",
        "  print('First GPU type: ',torch.cuda.get_device_name(0))\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOR4TGMFvPCB",
        "outputId": "978bfa79-e7f6-49ca-d61f-72c01978b096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (12000, 32, 32, 1)\n",
            "Y_train shape:  (12000,)\n",
            "X_vali shape:  (4000, 32, 32, 1)\n",
            "Y_vali shape:  (4000,)\n",
            "X_test shape:  (4000, 32, 32, 1)\n",
            "Y_test shape:  (4000,)\n"
          ]
        }
      ],
      "source": [
        "# preprocess data: split on training, validation, test\n",
        "# normalize fatures (pixels) in [0,1]\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
        "\n",
        "LOG_BINS = False\n",
        "Z_SCORE = True\n",
        "if Z_SCORE:\n",
        "  scaler = StandardScaler()\n",
        "else:\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "# training, validation, test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "testset_frac = 0.2 # test set fraction wrt whole samples\n",
        "valiset_frac = 0.25 # validation set fraction wrt training+validation\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(train_features,train_targets,test_size=testset_frac, shuffle=True, random_state=1234)\n",
        "X_train,X_vali,Y_train,Y_vali = train_test_split(X_train,Y_train,test_size=valiset_frac, shuffle=True, random_state=1234)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],32*32)\n",
        "X_vali = X_vali.reshape(X_vali.shape[0],32*32)\n",
        "X_test = X_test.reshape(X_test.shape[0],32*32)\n",
        "\n",
        "if LOG_BINS:\n",
        "    n_bin = 256\n",
        "    logbins = np.geomspace(X_train[X_train>0].min(), X_train.max(), n_bin)\n",
        "    X_train = np.digitize(X_train,logbins)\n",
        "    X_vali = np.digitize(X_vali,logbins)\n",
        "    X_test = np.digitize(X_test,logbins)\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_vali = scaler.transform(X_vali)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "else:\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_vali = scaler.transform(X_vali)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    \n",
        "X_train = X_train.reshape(X_train.shape[0],32,32)\n",
        "X_vali = X_vali.reshape(X_vali.shape[0],32,32)\n",
        "X_test = X_test.reshape(X_test.shape[0],32,32)\n",
        "\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_vali = np.expand_dims(X_vali, -1)\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        "\n",
        "print('X_train shape: ',X_train.shape)\n",
        "print('Y_train shape: ',Y_train.shape)\n",
        "print('X_vali shape: ',X_vali.shape)\n",
        "print('Y_vali shape: ',Y_vali.shape)\n",
        "print('X_test shape: ',X_test.shape)\n",
        "print('Y_test shape: ',Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2ERjZoepXzp"
      },
      "source": [
        "## Visualize the training set after the normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "WK4DrjgKpXzp",
        "outputId": "44e98fd1-c091-4923-f5b6-5335fd55b073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train max:  109.539955\n",
            "X_train min:  -0.8123182\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print('X_train max: ',X_train.max())\n",
        "print('X_train min: ',X_train.min())\n",
        "\n",
        "plt.figure(111)\n",
        "if LOG_BINS:\n",
        "  plt.hist(X_train[X_train>0].ravel(),logbins,density=True)\n",
        "else:\n",
        "    plt.hist(X_train[X_train>0].ravel(),density=True)\n",
        "\n",
        "plt.ylabel(\"pdf\")\n",
        "plt.xlabel(\"Intensities (Normalized)\")\n",
        "plt.xscale('log')\n",
        "plt.title(\"Histogram of Train set\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i+1)\n",
        "  ax.imshow(X_train[i,:,:,0], cmap='Blues')\n",
        "  ax.set_title(Y_train[i])\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RazSj3Fbv1L8",
        "outputId": "b7cb8198-e906-4cff-a37d-50ffd10da025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12000, 1, 32, 32])\n",
            "torch.Size([12000])\n",
            "torch.Size([4000, 1, 32, 32])\n",
            "torch.Size([4000])\n",
            "torch.Size([4000, 1, 32, 32])\n",
            "torch.Size([4000])\n"
          ]
        }
      ],
      "source": [
        "# transform numpy vectors to pytorch tensors\n",
        "X_train_pt = torch.Tensor(X_train)\n",
        "Y_train_pt = torch.Tensor(Y_train)\n",
        "X_vali_pt = torch.Tensor(X_vali)\n",
        "Y_vali_pt = torch.Tensor(Y_vali)\n",
        "X_test_pt = torch.Tensor(X_test)\n",
        "Y_test_pt = torch.Tensor(Y_test)\n",
        "\n",
        "# switch channel dimension position as needed by pytorch (NOTE: in numpy/keras (dim1,dim2,..., channels) in pytorch (channel, dim1, dim2, ...))\n",
        "X_train_pt = X_train_pt.permute(0,3,1,2)\n",
        "X_vali_pt = X_vali_pt.permute(0,3,1,2)\n",
        "X_test_pt = X_test_pt.permute(0,3,1,2)\n",
        "\n",
        "print(X_train_pt.shape)\n",
        "print(Y_train_pt.shape)\n",
        "print(X_vali_pt.shape)\n",
        "print(Y_vali_pt.shape)\n",
        "print(X_test_pt.shape)\n",
        "print(Y_test_pt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QUxEtUPZiSd"
      },
      "source": [
        "**Data generator definition**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8VATB6tdpXzs"
      },
      "outputs": [],
      "source": [
        "from operator import indexOf\n",
        "# create a custom dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# custom class that takes an image and outputs n_views random ransformation according to the \n",
        "# base_transforms list \n",
        "class ContrastiveTransformations(object):\n",
        "    def __init__(self, base_transforms):\n",
        "        self.base_transforms = base_transforms\n",
        "        \n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.base_transforms(x) \n",
        "\n",
        "class JetSubStructure(Dataset):\n",
        "    \"\"\"JetSubstructure dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, data, labels, phase='train', transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: torch tensor containing images\n",
        "            labels: torch tensor containing associated label\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.phase = phase\n",
        "        self.data = data\n",
        "        self.label = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        sample = self.data[idx]\n",
        "        label = self.label[idx]\n",
        "\n",
        "        if self.transform:\n",
        "          if self.phase == 'train':\n",
        "            sample = self.transform(sample)\n",
        "          else: \n",
        "            sample = sample\n",
        "\n",
        "        \n",
        "        return sample, label\n",
        "    \n",
        "# Data-augmentation transformations\n",
        "# compose 4 different transformations from the trochvision lib: random horizontal pixels flip, random vertical pixels flip, random rotation, and random crop of the image\n",
        "\n",
        "contrast_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomVerticalFlip(),\n",
        "                                          transforms.RandomRotation(180.),\n",
        "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                         ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X1FBKbIWpXzt"
      },
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "train_dataset = JetSubStructure(data=X_train_pt, labels=Y_train_pt, phase='train', transform=ContrastiveTransformations( base_transforms=contrast_transforms))\n",
        "val_dataset = JetSubStructure(data=X_vali_pt, labels=Y_vali_pt, phase='vali', transform=ContrastiveTransformations( base_transforms=contrast_transforms))\n",
        "test_dataset = JetSubStructure(data=X_test_pt, labels=Y_test_pt, phase='vali')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGtw59v3pXzu",
        "outputId": "1d7714cf-3066-4c07-b740-5dc93f0b9865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# We define a set of data loaders that we can use for various purposes later.\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, drop_last=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, drop_last=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "tg3EjzfPpXzu",
        "outputId": "f89e86fc-1a9c-491e-f58b-b42423c7f240"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize some examples\n",
        "NUM_IMAGES = 4\n",
        "images = torch.stack([val_dataset[idx][0] for idx in range(NUM_IMAGES)], dim=0)#first is image indx, second is image/label/\n",
        "img_grid = torchvision.utils.make_grid(images, nrow=4, normalize=True, pad_value=0.9)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Image examples of the dataset\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SFt6Mi-pXzv"
      },
      "source": [
        "## Transformers for image classification\n",
        "\n",
        "Transformers have been originally proposed to process sets (un-ordered lists of items) since it is a permutation-equivariant architecture, i.e., producing the same output permuted if the input is permuted. \n",
        "\n",
        "To apply Transformers to sequences (ordered lists), we need to add a positional encoding to the input feature vectors. Hopefully the model will learn by itself how to use this additional information.\n",
        "\n",
        "In this session we will work with images following the procedure proposed by Dosovitskiy et al.  in their paper \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\". \n",
        "\n",
        "Specifically, the Vision Transformer is a model for image classification that views images as sequences of smaller patches. \n",
        "\n",
        "As a preprocessing step, we need to divide the image in a sequence of small patches.\n",
        "\n",
        "Each of those patches is considered to be a \"word\"/\"token\" and projected to a feature space. \n",
        "\n",
        "Then we will add an a spatial encoding (additional paramenters that will encode the position of each patch in the larger image) to each patch. After this preprocessing we can apply a Transformer as usual to this sequence and start training it for our task.\n",
        "\n",
        "Transformenrs can work with high resolution images and learn how to use context from very distant portion of the image.\n",
        "\n",
        "\n",
        "Probably 64 patches of 8 pixels for these small images are a little too much... Try to optimize it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fl_zOWo7pXzv"
      },
      "outputs": [],
      "source": [
        "def img_to_patch(x, patch_size, flatten_channels=True):\n",
        "    # flatten channels is more importatnt as a parameter if we are working with multi channel images\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        x - torch.Tensor representing the image of shape [B, C, H, W]\n",
        "        patch_size - Number of pixels per dimension of the patches (integer)\n",
        "        flatten_channels - If True, the patches will be returned in a flattened format\n",
        "                           as a feature vector instead of a image grid.\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.shape\n",
        "    x = x.reshape(B, C, H//patch_size, patch_size, W//patch_size, patch_size)\n",
        "    x = x.permute(0, 2, 4, 1, 3, 5) # [B, H', W', C, p_H, p_W]\n",
        "    x = x.flatten(1,2)              # [B, H'*W', C, p_H, p_W]\n",
        "    if flatten_channels:\n",
        "        x = x.flatten(2,4)          # [B, H'*W', C*p_H*p_W]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "cYZUWE2NpXzv",
        "outputId": "92f6ae05-ebc0-4601-fa8f-f765f15ada7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x216 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "img_patches = img_to_patch(images, patch_size=8, flatten_channels=False)\n",
        "\n",
        "fig, ax = plt.subplots(images.shape[0], 1, figsize=(14,3))\n",
        "fig.suptitle(\"Images as input sequences of patches\")\n",
        "for i in range(images.shape[0]):\n",
        "    img_grid = torchvision.utils.make_grid(img_patches[i], nrow=64, normalize=True, pad_value=0.9)\n",
        "    img_grid = img_grid.permute(1, 2, 0)\n",
        "    ax[i].imshow(img_grid)\n",
        "    ax[i].axis('off')\n",
        "plt.show()\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXLE9QIDpXzw"
      },
      "source": [
        "Compared to the original images, it is much harder to recognize the objects from those patch lists now. Still, this is the input we provide to the Transformer for classifying the images. The model has to learn itself how it has to combine the patches to recognize the objects. The inductive bias in CNNs that an image is a grid of pixels, is lost in this input format.\n",
        "\n",
        "After we have looked at the preprocessing, we can now start building the Transformer model. \n",
        "\n",
        " Further, we use the Pre-Layer Normalization version of the Transformer blocks proposed by Ruibin Xiong et al. in 2020. \n",
        " \n",
        " The idea is to apply Layer Normalization not in between residual blocks, but instead as a first layer in the residual blocks. This reorganization of the layers supports better gradient flow and removes the necessity of a warm-up stage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PnZvnmOtpXzw"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, embed_dim, hidden_dim, num_heads, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            embed_dim - Dimensionality of input and attention feature vectors\n",
        "            hidden_dim - Dimensionality of hidden layer in feed-forward network \n",
        "                         (usually 2-4x larger than embed_dim)\n",
        "            num_heads - Number of heads to use in the Multi-Head Attention block\n",
        "            dropout - Amount of dropout to apply in the feed-forward network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "        self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(embed_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, embed_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        inp_x = self.layer_norm_1(x)\n",
        "        x = x + self.attn(inp_x, inp_x, inp_x)[0]\n",
        "        x = x + self.linear(self.layer_norm_2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDm_DbTpXzx"
      },
      "source": [
        "Now we have all modules ready to build our own Vision Transformer. Besides the Transformer encoder, we need the following modules:\n",
        "\n",
        "- A linear projection layer that maps the input patches to a feature vector of larger size. It is implemented by a simple linear layer that takes each patch independently as input.\n",
        "\n",
        "- A classification token that is added to the input sequence. We will use the output feature vector of the classification token (CLS token in short) for determining the classification prediction.\n",
        "\n",
        "- Learnable positional encodings that are added to the tokens before being processed by the Transformer. Those are needed to learn position-dependent information, and convert the set to a sequence. Since we usually work with a fixed resolution, we can learn the positional encodings instead of having the pattern of sine and cosine functions [Here you can find a good explanation of positional encodings for NLP sequences with varing length](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/).\n",
        "\n",
        "- An MLP head that takes the output feature vector of the CLS token, and maps it to a classification prediction. This is usually implemented by a small feed-forward network or even a single linear layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K4yL4Dr0pXzx"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, embed_dim, hidden_dim, num_channels, num_heads, num_layers, patch_size, num_patches, dropout=0.0):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            embed_dim - Dimensionality of the input feature vectors to the Transformer\n",
        "            hidden_dim - Dimensionality of the hidden layer in the feed-forward networks\n",
        "                         within the Transformer\n",
        "            num_channels - Number of channels of the input (3 for RGB)\n",
        "            num_heads - Number of heads to use in the Multi-Head Attention block\n",
        "            num_layers - Number of layers to use in the Transformer\n",
        "           \n",
        "            patch_size - Number of pixels that the patches have per dimension\n",
        "            num_patches - Maximum number of patches an image can have\n",
        "            dropout - Amount of dropout to apply in the feed-forward network and \n",
        "                      on the input encoding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.patch_size = patch_size\n",
        "        \n",
        "        # Layers/Networks\n",
        "        self.input_layer = nn.Linear(num_channels*(patch_size**2), embed_dim)\n",
        "        self.transformer = nn.Sequential(*[AttentionBlock(embed_dim, hidden_dim, num_heads, dropout=dropout) for _ in range(num_layers)])\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, 1),# cross entropy already has a softmax integrated while BCE does not. So a sigmoid is added # if **multiclass** this is the part to modify!\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Parameters/Embeddings\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1,embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1,1+num_patches,embed_dim))# this is our positional  embedding. It is initialized as a random number but it is learnable so it will be optimized during training.\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Preprocess input\n",
        "        x = img_to_patch(x, self.patch_size)\n",
        "        B, T, _ = x.shape\n",
        "        x = self.input_layer(x)\n",
        "        \n",
        "        # Add CLS token and positional encoding\n",
        "        cls_token = self.cls_token.repeat(B, 1, 1)\n",
        "        x = torch.cat([cls_token, x], dim=1)\n",
        "        x = x + self.pos_embedding[:,:T+1]\n",
        "        \n",
        "        # Apply Transforrmer\n",
        "        x = self.dropout(x)\n",
        "        x = x.transpose(0, 1)\n",
        "        x = self.transformer(x)\n",
        "        \n",
        "        # Perform classification prediction\n",
        "        cls = x[0]\n",
        "        out = self.mlp_head(cls)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BEuVeSUDpXzy"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_kwargs={\n",
        "                                'embed_dim': 64,\n",
        "                                'hidden_dim': 128,\n",
        "                                'num_heads': 8,\n",
        "                                'num_layers':4,\n",
        "                                'patch_size': 8,\n",
        "                                'num_channels': 1,\n",
        "                                'num_patches': 64,\n",
        "                                'dropout': 0.30\n",
        "                            }\n",
        "\n",
        "model = VisionTransformer(**model_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jegQIsiapXzy",
        "outputId": "745dd16f-07cb-401a-e479-e7eedfdb133f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1, 32, 32])\n",
            "torch.Size([256])\n"
          ]
        }
      ],
      "source": [
        "xb,yb=next(iter(val_loader))\n",
        "print(xb.shape)\n",
        "print(yb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sPr_jZPkpXzz"
      },
      "outputs": [],
      "source": [
        "out=model(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20UeL0-pXzz",
        "outputId": "3f2ae848-2512-4d4b-97e5-d4b22c78001b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 1])\n"
          ]
        }
      ],
      "source": [
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8K_vk2hpXzz",
        "outputId": "38fb8c80-4b06-4f1c-9168-d5914ed1cf40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
              "        0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
              "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
              "        0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
              "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
              "        0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        1., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXXGV9kupXz0",
        "outputId": "00eddddd-802d-4c7b-d8c8-b1aa2bc63437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (input_layer): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (transformer): Sequential(\n",
            "    (0): AttentionBlock(\n",
            "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (linear): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): GELU()\n",
            "        (2): Dropout(p=0.3, inplace=False)\n",
            "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "        (4): Dropout(p=0.3, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): AttentionBlock(\n",
            "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (linear): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): GELU()\n",
            "        (2): Dropout(p=0.3, inplace=False)\n",
            "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "        (4): Dropout(p=0.3, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): AttentionBlock(\n",
            "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (linear): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): GELU()\n",
            "        (2): Dropout(p=0.3, inplace=False)\n",
            "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "        (4): Dropout(p=0.3, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): AttentionBlock(\n",
            "      (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (linear): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): GELU()\n",
            "        (2): Dropout(p=0.3, inplace=False)\n",
            "        (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "        (4): Dropout(p=0.3, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mlp_head): Sequential(\n",
            "    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 16, 64]           4,160\n",
            "           Dropout-2               [-1, 17, 64]               0\n",
            "         LayerNorm-3                [-1, 2, 64]             128\n",
            "MultiheadAttention-4  [[-1, 2, 64], [-1, 17, 17]]               0\n",
            "         LayerNorm-5                [-1, 2, 64]             128\n",
            "            Linear-6               [-1, 2, 128]           8,320\n",
            "              GELU-7               [-1, 2, 128]               0\n",
            "           Dropout-8               [-1, 2, 128]               0\n",
            "            Linear-9                [-1, 2, 64]           8,256\n",
            "          Dropout-10                [-1, 2, 64]               0\n",
            "   AttentionBlock-11                [-1, 2, 64]               0\n",
            "        LayerNorm-12                [-1, 2, 64]             128\n",
            "MultiheadAttention-13  [[-1, 2, 64], [-1, 17, 17]]               0\n",
            "        LayerNorm-14                [-1, 2, 64]             128\n",
            "           Linear-15               [-1, 2, 128]           8,320\n",
            "             GELU-16               [-1, 2, 128]               0\n",
            "          Dropout-17               [-1, 2, 128]               0\n",
            "           Linear-18                [-1, 2, 64]           8,256\n",
            "          Dropout-19                [-1, 2, 64]               0\n",
            "   AttentionBlock-20                [-1, 2, 64]               0\n",
            "        LayerNorm-21                [-1, 2, 64]             128\n",
            "MultiheadAttention-22  [[-1, 2, 64], [-1, 17, 17]]               0\n",
            "        LayerNorm-23                [-1, 2, 64]             128\n",
            "           Linear-24               [-1, 2, 128]           8,320\n",
            "             GELU-25               [-1, 2, 128]               0\n",
            "          Dropout-26               [-1, 2, 128]               0\n",
            "           Linear-27                [-1, 2, 64]           8,256\n",
            "          Dropout-28                [-1, 2, 64]               0\n",
            "   AttentionBlock-29                [-1, 2, 64]               0\n",
            "        LayerNorm-30                [-1, 2, 64]             128\n",
            "MultiheadAttention-31  [[-1, 2, 64], [-1, 17, 17]]               0\n",
            "        LayerNorm-32                [-1, 2, 64]             128\n",
            "           Linear-33               [-1, 2, 128]           8,320\n",
            "             GELU-34               [-1, 2, 128]               0\n",
            "          Dropout-35               [-1, 2, 128]               0\n",
            "           Linear-36                [-1, 2, 64]           8,256\n",
            "          Dropout-37                [-1, 2, 64]               0\n",
            "   AttentionBlock-38                [-1, 2, 64]               0\n",
            "        LayerNorm-39                   [-1, 64]             128\n",
            "           Linear-40                    [-1, 1]              65\n",
            "          Sigmoid-41                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 71,681\n",
            "Trainable params: 71,681\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.07\n",
            "Params size (MB): 0.27\n",
            "Estimated Total Size (MB): 1.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(model)\n",
        "\n",
        "from torchsummary import summary\n",
        "if torch.cuda.is_available():\n",
        "  summary(model.cuda(), input_size=(1,32,32))\n",
        "else:\n",
        "  summary(model, input_size=(1,32,32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mIzEu_2pXz0",
        "outputId": "aee17c7f-bd2f-42cd-87ce-af90de27913a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is in the:  cpu\n",
            "now the model is in the:  cuda:0\n"
          ]
        }
      ],
      "source": [
        "#loss \n",
        "loss_func = nn.BCELoss() #binary cross entropy loss\n",
        "\n",
        "#metric accuracy\n",
        "def accuracy(out, yb):\n",
        "    preds = out.cpu().reshape(-1).detach().numpy().round()\n",
        "    return (preds == yb.cpu().detach().numpy()).mean()\n",
        "\n",
        "metric_func = accuracy\n",
        "\n",
        "# optim\n",
        "from torch import optim\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "lr_scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[25,50,80], gamma=0.2)\n",
        "\n",
        "# scheduler for step decay lr schedule\n",
        "#scheduler = optim.lr_scheduler.StepLR(opt, 10, gamma=0.1, last_epoch=-1, verbose=True)\n",
        "\n",
        "# move the model into the GPU\n",
        "model.to('cpu')\n",
        "print('The model is in the: ', next(model.parameters()).device)\n",
        "model.to(device)\n",
        "print('now the model is in the: ', next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-igtZOZkpXz1"
      },
      "outputs": [],
      "source": [
        "#Checkpoints (to save model parameters during training)\n",
        "class SaveBestModel:\n",
        "    def __init__(self, best_valid_loss=float('inf')): #object initialized with best_loss = +infinite\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        \n",
        "    def __call__(\n",
        "        self, current_valid_loss, \n",
        "        epoch, model, optimizer, criterion, metric,\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            # method to save a model (the state_dict: a python dictionary object that \n",
        "            # maps each layer to its parameter tensor) and other useful parametrers\n",
        "            # see: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                'metric': metric,\n",
        "                }, 'best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFU7LwBIpXz1",
        "outputId": "30f18fbe-2a82-44d7-83ce-38fdccb63fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best validation loss: 0.7179849781095982\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "epoch: 1, time(s): 10.96, train loss: 0.697497, train metric: 0.515795, vali loss: 0.717985, vali metric: 0.512012,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5894642099738121\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "epoch: 2, time(s): 10.87, train loss: 0.682137, train metric: 0.556471, vali loss: 0.589464, vali metric: 0.746289,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5573327615857124\n",
            "\n",
            "Saving best model for epoch: 3\n",
            "\n",
            "epoch: 3, time(s): 9.35, train loss: 0.647966, train metric: 0.625170, vali loss: 0.557333, vali metric: 0.731836,  lr : 1.00e-03\n",
            "epoch: 4, time(s): 7.36, train loss: 0.622178, train metric: 0.664062, vali loss: 0.608960, vali metric: 0.654834,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5380793958902359\n",
            "\n",
            "Saving best model for epoch: 5\n",
            "\n",
            "epoch: 5, time(s): 7.39, train loss: 0.615753, train metric: 0.666525, vali loss: 0.538079, vali metric: 0.743457,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5341639146208763\n",
            "\n",
            "Saving best model for epoch: 6\n",
            "\n",
            "epoch: 6, time(s): 7.23, train loss: 0.608925, train metric: 0.675696, vali loss: 0.534164, vali metric: 0.737012,  lr : 1.00e-03\n",
            "epoch: 7, time(s): 7.31, train loss: 0.595528, train metric: 0.688349, vali loss: 0.565318, vali metric: 0.717920,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5245625395327806\n",
            "\n",
            "Saving best model for epoch: 8\n",
            "\n",
            "epoch: 8, time(s): 7.25, train loss: 0.585693, train metric: 0.691236, vali loss: 0.524563, vali metric: 0.742041,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.522406816482544\n",
            "\n",
            "Saving best model for epoch: 9\n",
            "\n",
            "epoch: 9, time(s): 7.34, train loss: 0.582567, train metric: 0.698794, vali loss: 0.522407, vali metric: 0.741699,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.5094433687627316\n",
            "\n",
            "Saving best model for epoch: 10\n",
            "\n",
            "epoch: 10, time(s): 7.56, train loss: 0.575720, train metric: 0.708475, vali loss: 0.509443, vali metric: 0.753564,  lr : 1.00e-03\n",
            "epoch: 11, time(s): 7.32, train loss: 0.580997, train metric: 0.702021, vali loss: 0.534479, vali metric: 0.726807,  lr : 1.00e-03\n",
            "\n",
            "Best validation loss: 0.49048330821096897\n",
            "\n",
            "Saving best model for epoch: 12\n",
            "\n",
            "epoch: 12, time(s): 7.34, train loss: 0.569447, train metric: 0.706182, vali loss: 0.490483, vali metric: 0.756494,  lr : 1.00e-03\n",
            "epoch: 13, time(s): 7.71, train loss: 0.571926, train metric: 0.709069, vali loss: 0.494412, vali metric: 0.756348,  lr : 1.00e-03\n"
          ]
        }
      ],
      "source": [
        "#training loop\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "import time\n",
        "\n",
        "save_best_model = SaveBestModel()\n",
        "\n",
        "# lists to save loss and metric history\n",
        "hist_loss = []\n",
        "hist_metric = []\n",
        "hist_vloss = []\n",
        "hist_vmetric = []\n",
        "\n",
        "#loop over epochs\n",
        "for epoch in range(epochs):\n",
        "    t0 = time.time()\n",
        "\n",
        "    #training step\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_metric = 0.0\n",
        "    counter = 0\n",
        "    for xb, yb in train_loader: #takes a batch from the train dataloader \n",
        "        counter += 1 \n",
        "        xb=xb.type(torch.float).to(device) #move troch tensors to device (cpu or GPU)\n",
        "        yb=yb.type(torch.float).to(device)\n",
        "        \n",
        "        pred = model(xb) #get prediction for batch\n",
        "        loss = loss_func(pred, torch.unsqueeze(yb,1)) #compute loss\n",
        "        metric = metric_func(pred, yb) #compute metric\n",
        "\n",
        "        train_loss += loss.item() #update total loss\n",
        "        train_metric += metric.item() #update total metric\n",
        "\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update weights\n",
        "        opt.step()\n",
        "        # set to zero gradients for the next step\n",
        "        opt.zero_grad()\n",
        " \n",
        "    # normalize loss and metric by number of batches\n",
        "    train_loss = train_loss/counter\n",
        "    train_metric = train_metric/counter\n",
        "\n",
        "    # update history\n",
        "    hist_loss.append(train_loss)\n",
        "    hist_metric.append(train_metric)\n",
        "\n",
        "\n",
        "    # evaluation setp (same as trainign but w/o backpropagation)\n",
        "    model.eval()\n",
        "\n",
        "    vali_loss = 0.0\n",
        "    vali_metric = 0.0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "      for xb, yb in val_loader:\n",
        "        counter += 1\n",
        "        xb=xb.type(torch.float).to(device)\n",
        "        yb=yb.type(torch.float).to(device)\n",
        "        pred = model(xb)\n",
        "        vloss = loss_func(pred, torch.unsqueeze(yb,1))\n",
        "        vmetric = metric_func(pred, yb)\n",
        "        vali_loss += vloss.item()\n",
        "        vali_metric += vmetric.item()\n",
        "        \n",
        "    vali_loss = vali_loss/counter\n",
        "    vali_metric = vali_metric/counter    \n",
        "\n",
        "    hist_vloss.append(vali_loss)\n",
        "    hist_vmetric.append(vali_metric)\n",
        "\n",
        "    #save best model\n",
        "    save_best_model(vali_loss, epoch, model, opt, loss_func, metric_func)   \n",
        "\n",
        "    elapsed_time = time.time()-t0\n",
        "    current_lr = lr_scheduler.get_last_lr()[0]\n",
        "    print(\"epoch: %d, time(s): %.2f, train loss: %.6f, train metric: %.6f, vali loss: %.6f, vali metric: %.6f,  lr : %1.2e\" % (epoch+1, elapsed_time, train_loss, train_metric, vali_loss, vali_metric,current_lr))\n",
        "\n",
        "    # update learning rate schedule\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-g2o9P1pXz2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1,len(hist_loss)+1), hist_loss, color='green', linestyle='-', label='train loss')\n",
        "plt.plot(range(1,len(hist_vloss)+1), hist_vloss, color='blue', linestyle='-', label='validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1,len(hist_metric)+1), hist_metric,  color='green', linestyle='-', label='train metric')\n",
        "plt.plot(range(1,len(hist_vmetric)+1),hist_vmetric, color='blue', linestyle='-', label='validation metric')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ljtFX1QWrbPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AML_2022_5_VisionTransformer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}